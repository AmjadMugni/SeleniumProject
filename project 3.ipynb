{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-emperor",
   "metadata": {},
   "source": [
    "Q1.Write a python program which searches all the product under a particular product from\n",
    "www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user\n",
    "input is ‘guitar’. Then search for guitars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sunrise-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-c3898c42bce4>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "url = \"https://www.amazon.in\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "searchbar= driver.find_element_by_id('twotabsearchtextbox').send_keys(\"shoes\")\n",
    "search_button= driver.find_element_by_id(\"nav-search-submit-text\").click()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-mercury",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respected-relay",
   "metadata": {},
   "source": [
    "In the above question, now scrape the following details of each product listed in first 3 pages \n",
    "of your search results and save it in a dataframe and csv. In case if any product has less than 3 \n",
    "pages in search results then scrape all the products available under that product vertical. \n",
    "Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\", \n",
    "\"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it \n",
    "by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-chain",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "url = \"https://www.amazon.in\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "searchbar= driver.find_element_by_id('twotabsearchtextbox').send_keys(\"shoes\")\n",
    "search_button= driver.find_element_by_id(\"nav-search-submit-text\").click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "time.sleep(3)\n",
    "\n",
    "start=0\n",
    "end=7\n",
    "for page in range(start,end):\n",
    "    brands=driver.find_elements_by_class_name('a-size-base-plus a-color-base')\n",
    "    for i in brands:\n",
    "        brand.append(i.text)\n",
    "    desc=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "    for i in desc:\n",
    "        description.append(i.text)\n",
    "    prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//span[@class='Save']\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//li[@class='a-last']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "\n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand,\n",
    "                'Description':description,\n",
    "                'Price':price,\n",
    "                'Discount':discount})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-karaoke",
   "metadata": {},
   "source": [
    "3.Write a python program to access the search bar and search button on images.google.com and \n",
    "scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-moscow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "url = \"https://www.google.com/imghp?hl=EN\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "searchbar= driver.find_element_by_css_selector('input.gLFyf')\n",
    "searchbar.send_keys(\"Car\")\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='Tg7LZd']\").click()\n",
    "\n",
    "for i in range(1,100):\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot ('C:\\Users\\Sumain\\Desktop\\gitu\\car.png)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-number",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-selling",
   "metadata": {},
   "source": [
    "Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "url = \"https://www.google.com/imghp?hl=EN\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "searchbar= driver.find_element_by_css_selector('input.gLFyf')\n",
    "searchbar.send_keys(\"Fruits\")\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='Tg7LZd']\").click()\n",
    "\n",
    "for i in range(1,100):\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot ('C:\\Users\\Sumain\\Desktop\\gitu\\car.png)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-mouse",
   "metadata": {},
   "source": [
    "Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "url = \"https://www.google.com/imghp?hl=EN\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "searchbar= driver.find_element_by_css_selector('input.gLFyf')\n",
    "searchbar.send_keys(\"Machine Learning\")\n",
    "search_button= driver.find_element_by_xpath(\"//button[@class='Tg7LZd']\").click()\n",
    "\n",
    "for i in range(1,100):\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot ('C:\\Users\\Sumain\\Desktop\\gitu\\car.png)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-martin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adult-budapest",
   "metadata": {},
   "source": [
    "4.Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on \n",
    "www.flipkart.com and scrape following details for all the search results displayed on 1st page. \n",
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, \n",
    "“Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display \n",
    "Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. In \n",
    "case if any of the details is missing then replace it by “- “. Save your results in a dataframe \n",
    "and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-sweden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('smartphones')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "brand=[]\n",
    "price=[]\n",
    "RamRom=[]\n",
    "PrimaryCamera=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "   brands=driver.find_elements_by_class_name('_4rR01T')\n",
    "    for i in brands:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3 _1_WHN1']\")\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "\n",
    "    ramrom=driver.find_elements_by_xpath(\"//div[@class='rgWa7D']\")\n",
    "    for i in ramrom:\n",
    "        RamRom.append(i.text)   \n",
    "        \n",
    "    Pcamera=driver.find_elements_by_xpath(\"//div[@class='rgWa7D']\")\n",
    "    for i in ramrom:\n",
    "        PrimaryCamera.append(i.text) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "private-petroleum",
   "metadata": {},
   "source": [
    "5.Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on \n",
    "google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.google.co.in/maps/@10.8091781,78.2885026,7z\")\n",
    "sleep(2)\n",
    "  \n",
    "  \n",
    "# search locations\n",
    "def searchplace():\n",
    "    Place = driver.find_element_by_class_name(\"tactile-searchbox-input\")\n",
    "    Place.send_keys(\"Patna\")\n",
    "    Submit = driver.find_element_by_xpath(\n",
    "        \"/html/body/jsl/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/div[1]/button\")\n",
    "    Submit.click()\n",
    "\n",
    "  \n",
    "searchplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-collapse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "royal-anaheim",
   "metadata": {},
   "source": [
    "6.Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –\n",
    "September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.trak.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"menu-item-51510\"]').click()\n",
    "\n",
    "\n",
    "driver.find_elements_by_id('tablepress-57_wrapper')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
